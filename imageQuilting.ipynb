{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas a serem usadas pelo algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import builtins\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enum criado para melhorar organização do código, definindo vertical como índice 0 e horizontal como índice 1, quando necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Direction(Enum):\n",
    "    VERTICAL = 0\n",
    "    HORIZONTAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função helper que apenas mostra as imagens passadas na lista de imagens imgs e as mostra em janelas com nomes passados em names. Caso necessário, é possível escolher a escala das janelas a serem apresentadas usando scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(names, imgs, scaling = 1):\n",
    "    for i in range(len(names)):\n",
    "        cv.imshow(names[i], cv.resize(imgs[i], (imgs[i].shape[1] * scaling, imgs[i].shape[0] * scaling)))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função helper similar a show, mas não é passada lista de nomes para as janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fShow(imgs, scaling = 1):\n",
    "    for i in range(len(imgs)):\n",
    "        if imgs[i] is not None:\n",
    "            cv.imshow(\"image \" + str(i), cv.resize(imgs[i], (imgs[i].shape[1] * scaling, imgs[i].shape[0] * scaling)))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função helper que, dadas duas imagens, as corta para o menor retângulo que pode ser ocupada por ambas.\n",
    "Por exemplo, se é passada uma imagem 10x10 e uma imagem 11x9, retorna as duas imagens cortadas para o formato 10x9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutToSameShape(img1, img2):\n",
    "    if(img1.shape[0] != img2.shape[0]):\n",
    "        h = np.minimum(img1.shape[0], img2.shape[0])\n",
    "        img1 = img1[:h]\n",
    "        img2 = img2[:h]\n",
    "    if(img1.shape[1] != img2.shape[1]):\n",
    "        w = np.minimum(img1.shape[1], img2.shape[1])\n",
    "        img1 = img1[:,:w]\n",
    "        img2 = img2[:,:w]\n",
    "    return(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que computa (e retorna) a superficie de erro para a área de sobreposição de duas imagens (patches). \n",
    "Assume que img1 está, sempre, acima ou à esquerda de img2. \n",
    "boundarySize é a espessura da área de sobreposição. \n",
    "Caso direction seja vertical, entende-se que img1 está à esquerda de img2, e a borda entre elas tem orientação vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeErrorSurface(img1, img2, boundarySize: int, direction: Direction, verbose = False):\n",
    "    border1 = border2 = None\n",
    "    if direction == Direction.HORIZONTAL:\n",
    "        border1 = img1[-boundarySize-1:-1,:]\n",
    "        border2 = img2[0:boundarySize,:]\n",
    "    else:\n",
    "        border1 = img1[:,-boundarySize-1:-1]\n",
    "        border2 = img2[:,0:boundarySize]\n",
    "\n",
    "    border1,border2 = cutToSameShape(border1, border2)\n",
    "\n",
    "    if verbose:\n",
    "        fShow([border1,border2], 3)\n",
    "\n",
    "    diff = np.subtract(border1.astype(np.int),border2.astype(np.int))\n",
    "\n",
    "    squareDiff = np.square(diff)\n",
    "\n",
    "    ret = np.zeros((squareDiff.shape[0], squareDiff.shape[1]),dtype=np.uint32)\n",
    "\n",
    "    for i in range(ret.shape[0]):\n",
    "        for j in range(ret.shape[1]):\n",
    "            ret[i,j] = np.sum(squareDiff[i,j])\n",
    "\n",
    "    ret = np.sqrt(ret)\n",
    "    return cv.normalize(ret,None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções helper do algoritmo adaptado de Dijkstra. Retornam os vizinhos acessíveis a um pixel, dependendo se a borda (superfície de erro) sendo avaliada é horizontal ou vetical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verticalNeighbors(currentPos, errorBoundary):\n",
    "\n",
    "    neighbors = []\n",
    "\n",
    "    if(currentPos[0] != errorBoundary.shape[0]):\n",
    "        neighbors.append((currentPos[0] - 1, currentPos[1]))\n",
    "        if(currentPos[1] != 0):\n",
    "            neighbors.append((currentPos[0] - 1, currentPos[1] - 1))\n",
    "        if(currentPos[1] != errorBoundary.shape[1] - 1):\n",
    "            neighbors.append((currentPos[0] - 1, currentPos[1] + 1))\n",
    "    else:\n",
    "        for i in range(errorBoundary.shape[1]):\n",
    "            neighbors.append((currentPos[0] - 1, i))\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def horizontalNeighbors(currentPos, errorBoundary):\n",
    "\n",
    "    neighbors = []\n",
    "\n",
    "    if(currentPos[1] != errorBoundary.shape[1]):\n",
    "        neighbors.append((currentPos[0], currentPos[1] - 1))\n",
    "        if(currentPos[0] != 0):\n",
    "            neighbors.append((currentPos[0] - 1, currentPos[1] - 1))\n",
    "        if(currentPos[0] != errorBoundary.shape[0] - 1):\n",
    "            neighbors.append((currentPos[0] + 1, currentPos[1] - 1))\n",
    "    else:\n",
    "        for i in range(errorBoundary.shape[0]):\n",
    "            neighbors.append((i, currentPos[1] - 1))\n",
    "\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo adaptado de Dijkstra usado para computar o corte de borda de erro mínimo. Retorna lista o registro da distância entre a borda da imagem e o corte que deve ser feito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function heavily inspired by Ben Alex Keen's implementation: https://benalexkeen.com/implementing-djikstras-shortest-path-algorithm-with-python/\n",
    "def minimumBoundaryCutDjikstras(errorBoundary, direction: Direction):\n",
    "    dirIndex = direction.value\n",
    "    invDirIndex = (direction.value + 1) % 2\n",
    "    initial = [0,0]\n",
    "    initial[dirIndex] = errorBoundary.shape[dirIndex]\n",
    "    initial = tuple(initial)\n",
    "    \n",
    "    neighborFunction = verticalNeighbors\n",
    "\n",
    "    if(direction == Direction.HORIZONTAL):\n",
    "        neighborFunction = horizontalNeighbors\n",
    "\n",
    "    shortestPaths = {initial: (None, 0)}\n",
    "    currentNode = initial\n",
    "    visited = set()\n",
    "    \n",
    "    while currentNode[dirIndex] != 0:\n",
    "        visited.add(currentNode)\n",
    "        destinations = neighborFunction(currentNode, errorBoundary)\n",
    "        weightToCurrentNode = shortestPaths[currentNode][1]\n",
    "\n",
    "        for nextNode in destinations:\n",
    "            weight = errorBoundary[nextNode[0], nextNode[1]] + weightToCurrentNode\n",
    "            if nextNode not in shortestPaths:\n",
    "                shortestPaths[nextNode] = (currentNode, weight)\n",
    "            else:\n",
    "                currentShortestWeight = shortestPaths[nextNode][1]\n",
    "                if currentShortestWeight > weight:\n",
    "                    shortestPaths[nextNode] = (currentNode, weight)\n",
    "        \n",
    "        nextDestinations = {node: shortestPaths[node] for node in shortestPaths if node not in visited}\n",
    "        currentNode = builtins.min(nextDestinations, key=lambda k: nextDestinations[k][1])\n",
    "    \n",
    "    path = []\n",
    "    while currentNode is not None:\n",
    "        path.append(currentNode[invDirIndex])\n",
    "        nextNode = shortestPaths[currentNode][0]\n",
    "        currentNode = nextNode\n",
    "\n",
    "    return path[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que aplica patch em imagem maior.\n",
    "é passada a imagem maior em 'fullImg', o patch em 'patch', e a posição (índice, não pixel) na qual o patch deve ser aplicado, em 'position'. \n",
    "Esta posição é calculada a partir do tamanho do patch, que deve ser quadrado.\n",
    "'boundarySize' se refere à espessura da área de sobreposição/transição entre patches. 'cutUp' e 'cutLeft' se referem aos cortes a serem aplicados no patch, que são opcionais.\n",
    "Retorna 'fullImg' com o patch inserido na posição indicada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyWithMask(fullImg, patch, position, boundarySize, cutUp = None, cutLeft = None, verbose=False):\n",
    "    size = patch.shape[0] - boundarySize\n",
    "    pixelPosition = [position[0]*size, position[1]*size]\n",
    "    \n",
    "    patchForPasting = cv.cvtColor(patch, cv.COLOR_RGB2RGBA)\n",
    "    \n",
    "    patchForPasting[:,:,3] = 255\n",
    "    \n",
    "    if(cutUp != None):\n",
    "        np.clip(cutUp, 0, patchForPasting.shape[0] - 1)\n",
    "        \n",
    "        for i in range(patchForPasting.shape[1]):\n",
    "            if i < len(cutUp):\n",
    "                patchForPasting[:cutUp[i],i,3] = 0\n",
    "            else:\n",
    "                patchForPasting[:,i,3] = 0\n",
    "\n",
    "    if(cutLeft != None):\n",
    "        np.clip(cutLeft, 0, patchForPasting.shape[1] - 1)\n",
    "        for i in range(patchForPasting.shape[0]):\n",
    "            if i < len(cutLeft):\n",
    "                patchForPasting[i,:cutLeft[i],3] = 0\n",
    "            else:\n",
    "                patchForPasting[i,:,3] = 0\n",
    "\n",
    "    test = fullImg[pixelPosition[0]:pixelPosition[0] + patchForPasting.shape[0], pixelPosition[1]:pixelPosition[1] + patchForPasting.shape[1]].copy()\n",
    "\n",
    "    patchForPasting, _ = cutToSameShape(patchForPasting, test)\n",
    "    if verbose:\n",
    "        fShow([patchForPasting[:, :, :3]  * (patchForPasting[:, :, 3:] / 255)], 3)\n",
    "\n",
    "    fullImg[pixelPosition[0]:pixelPosition[0] + patchForPasting.shape[0], pixelPosition[1]:pixelPosition[1] + patchForPasting.shape[1]] = fullImg[pixelPosition[0]:pixelPosition[0] + patchForPasting.shape[0], pixelPosition[1]:pixelPosition[1] + patchForPasting.shape[1]] * (1 - patchForPasting[:, :, 3:] / 255) + patchForPasting[:, :, :3]  * (patchForPasting[:, :, 3:] / 255)\n",
    "    return fullImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computa o corte de borda de erro mínimo entre o patch atual (passado em 'currentImg') e as áreas acima e à esquerda do mesmo, passadas em 'upImg' e 'leftImg' respectivamente.\n",
    "Retorna lista com duas tuplas (uma para aborda vertical e outra para a horizontal). Cada tupla contém, no índice 0, o corte de erro mínimo, e no índice 1 a imagem da borda de erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMinimumBoundaryCut(currentImg, boundarySize, upImg = None, leftImg = None):\n",
    "    errorBoundaries = [(None, None), (None, None)]\n",
    "    boundaryFlag = [False, False]\n",
    "\n",
    "    if(upImg is not None):\n",
    "        e = computeErrorSurface(upImg, currentImg, boundarySize, Direction.HORIZONTAL)\n",
    "        errorBoundaries[Direction.HORIZONTAL.value] = e\n",
    "        boundaryFlag[Direction.HORIZONTAL.value] = True\n",
    "\n",
    "    if(leftImg is not None):\n",
    "        e = computeErrorSurface(leftImg, currentImg, boundarySize, Direction.VERTICAL)\n",
    "        errorBoundaries[Direction.VERTICAL.value] = e\n",
    "        boundaryFlag[Direction.VERTICAL.value] = True\n",
    "\n",
    "    if(boundaryFlag[0] and boundaryFlag[1]):\n",
    "        minima = np.minimum(errorBoundaries[0][:boundarySize, :boundarySize], errorBoundaries[1][:boundarySize, :boundarySize])\n",
    "        errorBoundaries[0][:boundarySize, :boundarySize] = errorBoundaries[1][:boundarySize, :boundarySize] = minima\n",
    "\n",
    "    if(boundaryFlag[Direction.HORIZONTAL.value]):\n",
    "        e = errorBoundaries[Direction.HORIZONTAL.value]\n",
    "        minCut = minimumBoundaryCutDjikstras(e, Direction.HORIZONTAL)\n",
    "        errorBoundaries[Direction.HORIZONTAL.value] = (minCut, e)\n",
    "\n",
    "    if(boundaryFlag[Direction.VERTICAL.value]):\n",
    "        e = errorBoundaries[Direction.VERTICAL.value]\n",
    "        minCut = minimumBoundaryCutDjikstras(e, Direction.VERTICAL)\n",
    "        errorBoundaries[Direction.VERTICAL.value] = (minCut, e)\n",
    "\n",
    "    return errorBoundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que retorna o erro entre as bordas do patch a ser aplicado e a imagem original na posição de aplicação. retorna esse valor entre 0 e 1. maxValue é usado para limitar o erro ao intervalo (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundaryError(canvas, patch, position, borderSize, maxValue):\n",
    "    mask = np.zeros(patch.shape, dtype=np.uint8)\n",
    "\n",
    "    if position[0] != 0:\n",
    "        mask[:borderSize,:] = 255\n",
    "\n",
    "    if position[2] != 0:\n",
    "        mask[:,:borderSize] = 255\n",
    "          \n",
    "    maskedPatch = cv.bitwise_and(patch, mask)\n",
    "    canvasSlice = canvas[position[0]:position[1], position[2]:position[3]]\n",
    "\n",
    "    maskedPatch, canvasSlice = cutToSameShape(maskedPatch, canvasSlice)\n",
    "    return np.sum(np.divide(np.absolute(np.subtract(maskedPatch.astype(np.float),canvasSlice.astype(np.float))),maxValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que calcula o erro entre os mapas de transferência na regiao com mesmo tamano que o patch sendo aplicado. Usa maxValue para limitar esse erro entre 0 e 1, e o retorna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspondenceError(textureMap, targetMap, texturePosition, targetPosition, maxValue):\n",
    "    texture = textureMap[texturePosition[0]:texturePosition[1], texturePosition[2]:texturePosition[3]]\n",
    "    target = targetMap[targetPosition[0]:targetPosition[1], targetPosition[2]:targetPosition[3]]\n",
    "\n",
    "    texture, target = cutToSameShape(texture, target)                                                                                                                         \n",
    "\n",
    "    return np.sum(np.divide(np.absolute(np.subtract(target.astype(np.float),texture.astype(np.float))),maxValue))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que, para a posição de aplicação passada, percorre toda a lista de patches guardando os n menores erros de aplicação/sobreposição encontrados. Retorna o id de um patch escolhido aleatoriamente entre esses n menores erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choosePatch(canvas, patches, positionId, cellSize, borderSize, textureMap, targetMap, patchSize, inputStep ,textureGridShape):\n",
    "    global randomness\n",
    "    bestPatch = collections.deque([(np.inf,0)], maxlen=randomness)\n",
    "    targetPosition = [positionId[0]*cellSize,(positionId[0] + 1)*cellSize + borderSize, positionId[1]*cellSize,(positionId[1]+1)*cellSize + borderSize]\n",
    "    maxValue = np.multiply(np.prod(patches[0].shape), 255)\n",
    "\n",
    "    global alpha\n",
    "    for i in range(len(patches)):\n",
    "        row = int(i/textureGridShape[1])*inputStep\n",
    "        col = (i%textureGridShape[1])*inputStep\n",
    "        \n",
    "        texturePosition = [row,row+patchSize, col,col+patchSize]\n",
    "        error = alpha*boundaryError(canvas, patches[i], targetPosition, borderSize, maxValue)\n",
    "        \n",
    "        if(alpha != 1):\n",
    "            error += (1-alpha)*correspondenceError(textureMap, targetMap, texturePosition, targetPosition,maxValue)\n",
    "\n",
    "        if error < bestPatch[0][0]:\n",
    "            bestPatch.appendleft((error, i))\n",
    "\n",
    "    return bestPatch[np.random.randint(len(bestPatch))][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que executa uma iteração do algoritmo Image Quilting, aplicando-a no canvas caso o mesmo seja passado. Se não for fornecido um canvas inicial, cria canvas preenchido com zeros. Retorna imgem preenchida com patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quiltCanvas(patches, targetGridSize, cellSize, borderSize, textureMap, targetMap, patchSize, inputStep, textureGridShape, canvas=None):\n",
    "    progress = 0\n",
    "    progressIncrease = 100/np.prod(targetGridSize)\n",
    "    \n",
    "    if canvas is None:\n",
    "        canvas = np.zeros((cellSize*targetGridSize[0] + borderSize, cellSize*targetGridSize[1] + borderSize, 3), dtype=np.uint8)\n",
    "    else:\n",
    "        canvas = canvas[:cellSize*targetGridSize[0] + borderSize, :cellSize*targetGridSize[1] + borderSize]\n",
    "    \n",
    "    for i in range(targetGridSize[0]):\n",
    "        for j in range(targetGridSize[1]):\n",
    "            try:\n",
    "                print(str(int(progress)) + '%')\n",
    "                progress += progressIncrease\n",
    "                \n",
    "                upCut = leftCut = upImg = leftImg = curImg = None\n",
    "                patchID = choosePatch(canvas, patches, (i,j), cellSize, borderSize, textureMap, targetMap, patchSize, inputStep, textureGridShape)\n",
    "\n",
    "                curImg = patches[patchID]\n",
    "\n",
    "                if i != 0:\n",
    "                    upImg = canvas[(i-1)*cellSize:(i)*cellSize + borderSize, j*cellSize:(j+1)*cellSize + borderSize]\n",
    "                if j != 0:\n",
    "                    leftImg = canvas[i*cellSize:(i+1)*cellSize + borderSize, (j-1)*cellSize:j*cellSize + borderSize]\n",
    "\n",
    "                temp = computeMinimumBoundaryCut(curImg, borderSize, upImg=upImg, leftImg=leftImg)\n",
    "                upCut = temp[Direction.HORIZONTAL.value][0]\n",
    "                leftCut = temp[Direction.VERTICAL.value][0]\n",
    "                canvas = applyWithMask(canvas, curImg, (i,j), borderSize, cutLeft = leftCut, cutUp=upCut)\n",
    "            except:\n",
    "                pass\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variável que seleciona o tipo de execução a ser feita. Ela existe somente para facilitar apresentação do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execution = 'basic example'\n",
    "#execution = 'texture synthesis'\n",
    "execution = 'texture transfer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que gera imagens para demonstrar funcionamento básico do algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution == 'basic example':\n",
    "    texture1 = cv.imread(\"./Testing/Input/noise1.jpg\", cv.IMREAD_COLOR)\n",
    "    texture2 = cv.imread(\"./Testing/Input/noise2.png\", cv.IMREAD_COLOR)\n",
    "    \n",
    "    fShow([texture1, texture2], 3)\n",
    "\n",
    "    errorBoundary = computeErrorSurface(texture2, texture1, 50, Direction.VERTICAL, True)\n",
    "\n",
    "    fShow([errorBoundary], 3)\n",
    "\n",
    "    cut = minimumBoundaryCutDjikstras(errorBoundary, Direction.VERTICAL)\n",
    "\n",
    "    cutImage = cv.merge((errorBoundary,errorBoundary,errorBoundary))\n",
    "    for i in range(len(cut)):\n",
    "        cutImage[i,cut[i]] = [0,255,0]\n",
    "\n",
    "    fShow([cutImage], 3)\n",
    "    canvas = np.zeros((int(texture1.shape[0]), int(2*texture1.shape[1]) - 50, 3), dtype=np.uint8)\n",
    "\n",
    "    canvas[:texture1.shape[0], :texture1.shape[1]] = texture1\n",
    "\n",
    "    canvas = applyWithMask(canvas, texture2, (0,1), 50, cutLeft = cut, verbose=True)\n",
    "\n",
    "    fShow([canvas], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que usa o algoritmo no modo de síntese de textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution == 'texture synthesis':\n",
    "    texturePath = \"./ComparissonPictures/Input/basket.png\"\n",
    "    textureSource = cv.imread(texturePath, cv.IMREAD_COLOR)\n",
    "    textureSource = cv.resize(textureSource, (int(textureSource.shape[1]), int(textureSource.shape[0])))\n",
    "\n",
    "    targetSource = cv.imread(texturePath, cv.IMREAD_COLOR)\n",
    "    targetSource = cv.resize(targetSource, (int(targetSource.shape[1]*2), int(targetSource.shape[0]*2)))\n",
    "\n",
    "    textureMap =    cv.GaussianBlur(cv.cvtColor(textureSource, cv.COLOR_BGR2GRAY), (9,9), 0.5)\n",
    "    targetMap  =    cv.GaussianBlur(cv.cvtColor(targetSource, cv.COLOR_BGR2GRAY), (9,9), 0.5)\n",
    "\n",
    "    canvas = None\n",
    "\n",
    "    patchSize = 100\n",
    "    inputStep = 10\n",
    "    randomness = 2\n",
    "    borderRatio = 4\n",
    "    alpha = 1\n",
    "    \n",
    "    borderSize = int(patchSize/borderRatio)\n",
    "    cellSize = patchSize - borderSize\n",
    "\n",
    "    targetGridSize = (int(targetSource.shape[0]/cellSize),int(targetSource.shape[1]/cellSize))\n",
    "    textureGridShape = (int((textureSource.shape[0] - patchSize)/inputStep),int((textureSource.shape[1] - patchSize)/inputStep))\n",
    "\n",
    "    patches = []\n",
    "    for i in range(textureGridShape[0]):\n",
    "        for j in range(textureGridShape[1]):\n",
    "            patches.append(textureSource[i*inputStep:i*inputStep + patchSize, j*inputStep:j*inputStep + patchSize].copy())\n",
    "    \n",
    "    canvas = quiltCanvas(patches, targetGridSize, cellSize, borderSize, textureMap, targetMap, patchSize, inputStep, textureGridShape, canvas=canvas)\n",
    "\n",
    "    show([\"texture\", \"output\"], [textureSource, canvas], 2)\n",
    "\n",
    "    cv.imwrite('./Testing/Output/texture_synthesis_' + '_'.join((str(randomness), str(alpha), str(patchSize), str(borderRatio))) + '.png', canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que usa o algoritmo no modo de transferência de textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "0%\n",
      "0%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "2%\n",
      "2%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "4%\n",
      "4%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "6%\n",
      "6%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "8%\n",
      "8%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "10%\n",
      "10%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "12%\n",
      "12%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "14%\n",
      "14%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "16%\n",
      "16%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "18%\n",
      "18%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "20%\n",
      "20%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "22%\n",
      "22%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "25%\n",
      "25%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "27%\n",
      "27%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "29%\n",
      "29%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "31%\n",
      "31%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "33%\n",
      "33%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "35%\n",
      "35%\n",
      "36%\n",
      "36%\n",
      "36%\n",
      "37%\n",
      "37%\n",
      "38%\n",
      "38%\n",
      "38%\n",
      "39%\n",
      "39%\n",
      "40%\n",
      "40%\n",
      "40%\n",
      "41%\n",
      "41%\n",
      "42%\n",
      "42%\n",
      "42%\n",
      "43%\n",
      "43%\n",
      "44%\n",
      "44%\n",
      "44%\n",
      "45%\n",
      "45%\n",
      "46%\n",
      "46%\n",
      "46%\n",
      "47%\n",
      "47%\n",
      "48%\n",
      "48%\n",
      "48%\n",
      "49%\n",
      "49%\n",
      "50%\n",
      "50%\n",
      "50%\n",
      "51%\n",
      "51%\n",
      "51%\n",
      "52%\n",
      "52%\n",
      "53%\n",
      "53%\n",
      "53%\n",
      "54%\n",
      "54%\n",
      "55%\n",
      "55%\n",
      "55%\n",
      "56%\n",
      "56%\n",
      "57%\n",
      "57%\n",
      "57%\n",
      "58%\n",
      "58%\n",
      "59%\n",
      "59%\n",
      "59%\n",
      "60%\n",
      "60%\n",
      "61%\n",
      "61%\n",
      "61%\n",
      "62%\n",
      "62%\n",
      "63%\n",
      "63%\n",
      "63%\n",
      "64%\n",
      "64%\n",
      "65%\n",
      "65%\n",
      "65%\n",
      "66%\n",
      "66%\n",
      "67%\n",
      "67%\n",
      "67%\n",
      "68%\n",
      "68%\n",
      "69%\n",
      "69%\n",
      "69%\n",
      "70%\n",
      "70%\n",
      "71%\n",
      "71%\n",
      "71%\n",
      "72%\n",
      "72%\n",
      "73%\n",
      "73%\n",
      "73%\n",
      "74%\n",
      "74%\n",
      "74%\n",
      "75%\n",
      "75%\n",
      "76%\n",
      "76%\n",
      "76%\n",
      "77%\n",
      "77%\n",
      "78%\n",
      "78%\n",
      "78%\n",
      "79%\n",
      "79%\n",
      "80%\n",
      "80%\n",
      "80%\n",
      "81%\n",
      "81%\n",
      "82%\n",
      "82%\n",
      "82%\n",
      "83%\n",
      "83%\n",
      "84%\n",
      "84%\n",
      "84%\n",
      "85%\n",
      "85%\n",
      "86%\n",
      "86%\n",
      "86%\n",
      "87%\n",
      "87%\n",
      "88%\n",
      "88%\n",
      "88%\n",
      "89%\n",
      "89%\n",
      "90%\n",
      "90%\n",
      "90%\n",
      "91%\n",
      "91%\n",
      "92%\n",
      "92%\n",
      "92%\n",
      "93%\n",
      "93%\n",
      "94%\n",
      "94%\n",
      "94%\n",
      "95%\n",
      "95%\n",
      "96%\n",
      "96%\n",
      "96%\n",
      "97%\n",
      "97%\n",
      "98%\n",
      "98%\n",
      "98%\n",
      "99%\n",
      "99%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "36%\n",
      "36%\n",
      "36%\n",
      "36%\n",
      "36%\n",
      "36%\n",
      "37%\n",
      "37%\n",
      "37%\n",
      "37%\n",
      "37%\n",
      "37%\n",
      "38%\n",
      "38%\n",
      "38%\n",
      "38%\n",
      "38%\n",
      "38%\n",
      "39%\n",
      "39%\n",
      "39%\n",
      "39%\n",
      "39%\n",
      "39%\n",
      "40%\n",
      "40%\n",
      "40%\n",
      "40%\n",
      "40%\n",
      "40%\n",
      "41%\n",
      "41%\n",
      "41%\n",
      "41%\n",
      "41%\n",
      "42%\n",
      "42%\n",
      "42%\n",
      "42%\n",
      "42%\n",
      "42%\n",
      "43%\n",
      "43%\n",
      "43%\n",
      "43%\n",
      "43%\n",
      "43%\n",
      "44%\n",
      "44%\n",
      "44%\n",
      "44%\n",
      "44%\n",
      "44%\n",
      "45%\n",
      "45%\n",
      "45%\n",
      "45%\n",
      "45%\n",
      "45%\n",
      "46%\n",
      "46%\n",
      "46%\n",
      "46%\n",
      "46%\n",
      "46%\n",
      "47%\n",
      "47%\n",
      "47%\n",
      "47%\n",
      "47%\n",
      "47%\n",
      "48%\n",
      "48%\n",
      "48%\n",
      "48%\n",
      "48%\n",
      "48%\n",
      "49%\n",
      "49%\n",
      "49%\n",
      "49%\n",
      "49%\n",
      "49%\n",
      "50%\n",
      "50%\n",
      "50%\n",
      "50%\n",
      "50%\n",
      "51%\n",
      "51%\n",
      "51%\n",
      "51%\n",
      "51%\n",
      "51%\n",
      "52%\n",
      "52%\n",
      "52%\n",
      "52%\n",
      "52%\n",
      "52%\n",
      "53%\n",
      "53%\n",
      "53%\n",
      "53%\n",
      "53%\n",
      "53%\n",
      "54%\n",
      "54%\n",
      "54%\n",
      "54%\n",
      "54%\n",
      "54%\n",
      "55%\n",
      "55%\n",
      "55%\n",
      "55%\n",
      "55%\n",
      "55%\n",
      "56%\n",
      "56%\n",
      "56%\n",
      "56%\n",
      "56%\n",
      "56%\n",
      "57%\n",
      "57%\n",
      "57%\n",
      "57%\n",
      "57%\n",
      "57%\n",
      "58%\n",
      "58%\n",
      "58%\n",
      "58%\n",
      "58%\n",
      "59%\n",
      "59%\n",
      "59%\n",
      "59%\n",
      "59%\n",
      "59%\n",
      "60%\n",
      "60%\n",
      "60%\n",
      "60%\n",
      "60%\n",
      "60%\n",
      "61%\n",
      "61%\n",
      "61%\n",
      "61%\n",
      "61%\n",
      "61%\n",
      "62%\n",
      "62%\n",
      "62%\n",
      "62%\n",
      "62%\n",
      "62%\n",
      "63%\n",
      "63%\n",
      "63%\n",
      "63%\n",
      "63%\n",
      "63%\n",
      "64%\n",
      "64%\n",
      "64%\n",
      "64%\n",
      "64%\n",
      "64%\n",
      "65%\n",
      "65%\n",
      "65%\n",
      "65%\n",
      "65%\n",
      "65%\n",
      "66%\n",
      "66%\n",
      "66%\n",
      "66%\n",
      "66%\n",
      "67%\n",
      "67%\n",
      "67%\n",
      "67%\n",
      "67%\n",
      "67%\n",
      "68%\n",
      "68%\n",
      "68%\n",
      "68%\n",
      "68%\n",
      "68%\n",
      "69%\n",
      "69%\n",
      "69%\n",
      "69%\n",
      "69%\n",
      "69%\n",
      "70%\n",
      "70%\n",
      "70%\n",
      "70%\n",
      "70%\n",
      "70%\n",
      "71%\n",
      "71%\n",
      "71%\n",
      "71%\n",
      "71%\n",
      "71%\n",
      "72%\n",
      "72%\n",
      "72%\n",
      "72%\n",
      "72%\n",
      "72%\n",
      "73%\n",
      "73%\n",
      "73%\n",
      "73%\n",
      "73%\n",
      "73%\n",
      "74%\n",
      "74%\n",
      "74%\n",
      "74%\n",
      "74%\n",
      "74%\n",
      "75%\n",
      "75%\n",
      "75%\n",
      "75%\n",
      "75%\n",
      "76%\n",
      "76%\n",
      "76%\n",
      "76%\n",
      "76%\n",
      "76%\n",
      "77%\n",
      "77%\n",
      "77%\n",
      "77%\n",
      "77%\n",
      "77%\n",
      "78%\n",
      "78%\n",
      "78%\n",
      "78%\n",
      "78%\n",
      "78%\n",
      "79%\n",
      "79%\n",
      "79%\n",
      "79%\n",
      "79%\n",
      "79%\n",
      "80%\n",
      "80%\n",
      "80%\n",
      "80%\n",
      "80%\n",
      "80%\n",
      "81%\n",
      "81%\n",
      "81%\n",
      "81%\n",
      "81%\n",
      "81%\n",
      "82%\n",
      "82%\n",
      "82%\n",
      "82%\n",
      "82%\n",
      "82%\n",
      "83%\n",
      "83%\n",
      "83%\n",
      "83%\n",
      "83%\n",
      "84%\n",
      "84%\n",
      "84%\n",
      "84%\n",
      "84%\n",
      "84%\n",
      "85%\n",
      "85%\n",
      "85%\n",
      "85%\n",
      "85%\n",
      "85%\n",
      "86%\n",
      "86%\n",
      "86%\n",
      "86%\n",
      "86%\n",
      "86%\n",
      "87%\n",
      "87%\n",
      "87%\n",
      "87%\n",
      "87%\n",
      "87%\n",
      "88%\n",
      "88%\n",
      "88%\n",
      "88%\n",
      "88%\n",
      "88%\n",
      "89%\n",
      "89%\n",
      "89%\n",
      "89%\n",
      "89%\n",
      "89%\n",
      "90%\n",
      "90%\n",
      "90%\n",
      "90%\n",
      "90%\n",
      "90%\n",
      "91%\n",
      "91%\n",
      "91%\n",
      "91%\n",
      "91%\n",
      "92%\n",
      "92%\n",
      "92%\n",
      "92%\n",
      "92%\n",
      "92%\n",
      "93%\n",
      "93%\n",
      "93%\n",
      "93%\n",
      "93%\n",
      "93%\n",
      "94%\n",
      "94%\n",
      "94%\n",
      "94%\n",
      "94%\n",
      "94%\n",
      "95%\n",
      "95%\n",
      "95%\n",
      "95%\n",
      "95%\n",
      "95%\n",
      "96%\n",
      "96%\n",
      "96%\n",
      "96%\n",
      "96%\n",
      "96%\n",
      "97%\n",
      "97%\n",
      "97%\n",
      "97%\n",
      "97%\n",
      "97%\n",
      "98%\n",
      "98%\n",
      "98%\n",
      "98%\n",
      "98%\n",
      "98%\n",
      "99%\n",
      "99%\n",
      "99%\n",
      "99%\n",
      "99%\n"
     ]
    }
   ],
   "source": [
    "if execution == 'texture transfer':\n",
    "    textureSource = cv.imread(\"./comparissonPictures/Input/textura.png\", cv.IMREAD_COLOR)\n",
    "\n",
    "    textureSource = cv.resize(textureSource, (int(textureSource.shape[1]/2), int(textureSource.shape[0]/2)))\n",
    "\n",
    "    targetSource = cv.imread(\"./comparissonPictures/Input/alvo.png\", cv.IMREAD_COLOR)\n",
    "    targetSource = cv.resize(targetSource, (int(targetSource.shape[1]), int(targetSource.shape[0])))\n",
    "\n",
    "    textureMap =    cv.GaussianBlur(cv.cvtColor(textureSource, cv.COLOR_BGR2GRAY), (11,11), 1)\n",
    "    targetMap  =    cv.GaussianBlur(cv.cvtColor(targetSource, cv.COLOR_BGR2GRAY), (11,11), 1)\n",
    "\n",
    "    textureMap = cv.equalizeHist(textureMap)\n",
    "    targetMap = cv.equalizeHist(targetMap)\n",
    "\n",
    "    fShow([textureMap, targetMap])\n",
    "\n",
    "    canvas = None\n",
    "\n",
    "    initialPatchSize = 50\n",
    "    inputStep = 15\n",
    "    randomness = 5\n",
    "    borderRatio = 4\n",
    "    N = 1\n",
    "\n",
    "    patchSize = initialPatchSize*3/2\n",
    "    for i in range(N+1):\n",
    "        alpha =  0.5*(i/N) + 0.1\n",
    "        patchSize = int(patchSize*2/3)\n",
    "        borderSize = int(patchSize/borderRatio)\n",
    "        cellSize = patchSize - borderSize\n",
    "\n",
    "        if(borderSize == 0 or patchSize < inputStep):\n",
    "            break\n",
    "\n",
    "        targetGridSize = (int(targetSource.shape[0]/cellSize),int(targetSource.shape[1]/cellSize))\n",
    "        textureGridShape = (int((textureSource.shape[0] - patchSize)/inputStep),int((textureSource.shape[1] - patchSize)/inputStep))\n",
    "\n",
    "        patches = []\n",
    "        for i in range(textureGridShape[0]):\n",
    "            for j in range(textureGridShape[1]):\n",
    "                patches.append(textureSource[i*inputStep:i*inputStep + patchSize, j*inputStep:j*inputStep + patchSize].copy())\n",
    "\n",
    "        canvas = quiltCanvas(patches, targetGridSize, cellSize, borderSize, textureMap, targetMap, patchSize, inputStep, textureGridShape, canvas=canvas)\n",
    "\n",
    "        show([\"texture\", \"target\", \"output\"], [textureSource, targetSource, canvas])\n",
    "\n",
    "    cv.imwrite('./Testing/Output/texture_transfer_' + '_'.join((str(randomness), str(alpha), str(patchSize), str(borderRatio))) + '.png', canvas)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9868c5b6e0ca526c7e6a4d00153652fb4847ae9eb0770cba91422c0bf7b51d41"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
